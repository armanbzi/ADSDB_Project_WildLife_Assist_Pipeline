{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63edc53b-d9a5-4cc4-ac58-2b833c652536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-Arman Bazarchi-\n",
    "Persistent_Landing Zone\n",
    "here we retrieve the stored raw data in temporal-landing and place them more organized in persistent-landing.\n",
    "connects to minIO and creates a persistent_landing subbucket in temporal-zone bucket,\n",
    "raises an error if the temporal_landing subbucket or temporal-zone bucket does not exist.\n",
    "saves text data in a csv file in a folder 'metadata',\n",
    "saves each image in its specie folder inside its family folder, inside its class, inside the kingdom it belongs to.\n",
    "so we ensure organized data having easy access to each one.\n",
    "example path of each image: temporal-zone/persistent_landing/images/{kingdom}/{class}/{family}/{specie}/{img_uuid}.jpg\n",
    "it avoids storing duplicate data in persistent_landing.\n",
    "in end removes temporary files from local storage and delets the temporal_landing as we have now moved the data to persistent.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from minio import Minio\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# ==============================\n",
    "# 1.  Configuration\n",
    "# ==============================\n",
    "def process_landing_zone(\n",
    "    MINIO=\"localhost:9000\",\n",
    "    ACCESS_KEY=\"admin\",\n",
    "    SECRET_KEY=\"password123\"): \n",
    "    \n",
    "\n",
    "    ROOT_BUCKET=\"temporal-zone\" # main bucket\n",
    "    TEMP_PREFIX=\"temporal-landing\" # source bucket\n",
    "    PERSIST_PREFIX=\"persistent_landing\" # destination bucket\n",
    "    #  Connect to MinIO\n",
    "    client = Minio(\n",
    "        MINIO,\n",
    "        access_key=ACCESS_KEY,\n",
    "        secret_key=SECRET_KEY,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #  Validate buckets\n",
    "    if not client.bucket_exists(ROOT_BUCKET):\n",
    "        sys.exit(\" ERROR: Root bucket 'Landing' does not exist in MinIO.\")\n",
    "    \n",
    "    temporal_exists = any(\n",
    "        obj.object_name.startswith(f\"{TEMP_PREFIX}/\")\n",
    "        for obj in client.list_objects(ROOT_BUCKET, recursive=False)\n",
    "    )\n",
    "    if not temporal_exists:\n",
    "        sys.exit(\" ERROR: 'Temporal_Landing' does not exist inside 'Landing' bucket.\")\n",
    "    \n",
    "    # Create Persistent_Landing if missing\n",
    "    persistent_exists = any(\n",
    "        obj.object_name.startswith(f\"{PERSIST_PREFIX}/\")\n",
    "        for obj in client.list_objects(ROOT_BUCKET, recursive=False)\n",
    "    )\n",
    "    if not persistent_exists:\n",
    "        client.put_object(\n",
    "            ROOT_BUCKET,\n",
    "            f\"{PERSIST_PREFIX}/.init\",\n",
    "            data=io.BytesIO(b\"init\"),\n",
    "            length=4,\n",
    "            content_type=\"text/plain\"\n",
    "        )\n",
    "        print(f\" Created 'Persistent_Landing' inside '{ROOT_BUCKET}'.\")\n",
    "    \n",
    "    # ==============================\n",
    "    # 2. Load metadata from Temporal_Landing\n",
    "    # ==============================\n",
    "    print(\"ðŸ“¥ Loading metadata from Temporal_Landing...\")\n",
    "    LOCAL_METADATA = \"temp_metadata.csv\"\n",
    "    TEMP_METADATA_PATH = f\"{TEMP_PREFIX}/metadata/metadata_final.csv\"\n",
    "    try:\n",
    "        client.fget_object(ROOT_BUCKET, TEMP_METADATA_PATH, LOCAL_METADATA)\n",
    "    except Exception as e:\n",
    "        sys.exit(f\" ERROR: Failed to find metadata at {TEMP_METADATA_PATH} â†’ {e}\")\n",
    "    \n",
    "    metadata_df = pd.read_csv(LOCAL_METADATA)\n",
    "    print(f\" Loaded metadata with {len(metadata_df)} records.\")\n",
    "    \n",
    "    # ==============================\n",
    "    # 3. Scan existing Persistent images by UUID\n",
    "    # ==============================\n",
    "    print(\" Checking existing images in Persistent_Landing...\")\n",
    "    existing_persistent_uuids = set()\n",
    "    for obj in client.list_objects(ROOT_BUCKET, prefix=f\"{PERSIST_PREFIX}/images/\", recursive=True):\n",
    "        match = re.match(rf\"{PERSIST_PREFIX}/images/.+?/([a-f0-9\\-]+)\\.jpg\", obj.object_name)\n",
    "        if match:\n",
    "            existing_persistent_uuids.add(match.group(1))\n",
    "    \n",
    "    print(f\" Found {len(existing_persistent_uuids)} existing images in Persistent_Landing.\")\n",
    "    metadata_df[\"persistent_path\"] = None\n",
    "    \n",
    "    # ==============================\n",
    "    # 4. Move images from Temporal -> Persistent\n",
    "    # ==============================\n",
    "    timestamp = datetime.now().strftime(\"%Y_%m_%d_%H:%M\")\n",
    "    moved_records = []\n",
    "    \n",
    "    for idx, row in metadata_df.iterrows():\n",
    "        try:\n",
    "            img_uuid = row.get(\"uuid\")\n",
    "            if not img_uuid:\n",
    "                continue\n",
    "    \n",
    "            # Skip if image already exists in Persistent\n",
    "            if img_uuid in existing_persistent_uuids:\n",
    "                print(f\" Skipping duplicate UUID: {img_uuid}\")\n",
    "                continue\n",
    "    \n",
    "            object_name = row.get(\"temporal_path\") \n",
    "            src_path = object_name\n",
    "    \n",
    "            kingdom = str(row.get(\"kingdom\", \"Unknown\")).replace(\" \", \"_\")\n",
    "            cls = str(row.get(\"class\", \"Unknown\")).replace(\" \", \"_\")\n",
    "            family = str(row.get(\"family\", \"Unknown\")).replace(\" \", \"_\")\n",
    "            specie = str(row.get(\"species\", \"Unknown\")).replace(\" \", \"_\")\n",
    "    \n",
    "            # Destination path \n",
    "            dest_path = f\"{PERSIST_PREFIX}/images/{kingdom}/{cls}/{family}/{specie}/{img_uuid}.jpg\"\n",
    "            metadata_df.loc[idx, \"persistent_path\"] = dest_path\n",
    "            \n",
    "            # Download image from Temporal\n",
    "            data = client.get_object(ROOT_BUCKET, src_path)\n",
    "            image_bytes = data.read()\n",
    "            data.close()\n",
    "            data.release_conn()\n",
    "    \n",
    "            # Upload image to Persistent\n",
    "            client.put_object(\n",
    "                ROOT_BUCKET,\n",
    "                dest_path,\n",
    "                data=io.BytesIO(image_bytes),\n",
    "                length=len(image_bytes),\n",
    "                content_type=\"image/jpeg\"\n",
    "            )\n",
    "    \n",
    "            \n",
    "            moved_records.append(row)\n",
    "            existing_persistent_uuids.add(img_uuid)\n",
    "    \n",
    "            print(f\" Moved {src_path} â†’ {dest_path}\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\" Error processing {object_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # ==============================\n",
    "    # 5. Save or merge metadata files by (Kingdom, Class)\n",
    "    # we store for each class of a kingdom a seperate metadata\n",
    "    # if storing different classes or kingdoms in future, we will have seperat for each for easy access\n",
    "    # ==============================\n",
    "    if not metadata_df.empty:\n",
    "        print(\" Updating kingdom-class based metadata files...\")\n",
    "    \n",
    "        for (kingdom_name, cls_name), group in metadata_df.groupby([\"kingdom\", \"class\"]):\n",
    "            kingdom_safe = str(kingdom_name).replace(\" \", \"_\")\n",
    "            cls_safe = str(cls_name).replace(\" \", \"_\")\n",
    "    \n",
    "            #  create a new filename with current timestamp for updated metadata\n",
    "            timestamp = datetime.now().strftime(\"%Y_%m_%d_%H:%M\")\n",
    "            metadata_filename = f\"{kingdom_safe}_{cls_safe}_metadata_{timestamp}.csv\"\n",
    "            local_metadata_file = f\"{kingdom_safe}_{cls_safe}_metadata_temp.csv\"\n",
    "            persistent_metadata_dir = f\"{PERSIST_PREFIX}/metadata/\"\n",
    "    \n",
    "            # Look for any existing metadata file for this kingdom+class\n",
    "            existing_metadata_files = [\n",
    "                obj.object_name for obj in client.list_objects(ROOT_BUCKET, prefix=persistent_metadata_dir, recursive=True)\n",
    "                if re.match(rf\"{persistent_metadata_dir}{kingdom_safe}_{cls_safe}_metadata_.*\\.csv\", obj.object_name)\n",
    "            ]\n",
    "    \n",
    "            if existing_metadata_files:\n",
    "                # Take the latest metadata file (any timestamp)\n",
    "                existing_metadata_files.sort(reverse=True)\n",
    "                existing_metadata_path = existing_metadata_files[0]\n",
    "                existing_local_file = f\"existing_{kingdom_safe}_{cls_safe}.csv\"\n",
    "                client.fget_object(ROOT_BUCKET, existing_metadata_path, existing_local_file)\n",
    "    \n",
    "                # Read existing metadata\n",
    "                existing_df = pd.read_csv(existing_local_file)\n",
    "    \n",
    "                # Delete old file from Persistent\n",
    "                client.remove_object(ROOT_BUCKET, existing_metadata_path)\n",
    "                os.remove(existing_local_file)\n",
    "    \n",
    "                # Merge Temporal rows that are not already in Persistent\n",
    "                new_rows = group[~group[\"uuid\"].isin(existing_df[\"uuid\"])]\n",
    "                merged_df = pd.concat([existing_df, new_rows], ignore_index=True)\n",
    "            else:\n",
    "                # No existing metadata -> use all rows from Temporal\n",
    "                group[\"persistent_path\"]\n",
    "                merged_df = group\n",
    "    \n",
    "            # Save merged metadata with updated timestamp\n",
    "            merged_df.to_csv(local_metadata_file, index=False)\n",
    "            persistent_metadata_path_new = f\"{persistent_metadata_dir}{metadata_filename}\"\n",
    "            client.fput_object(\n",
    "                ROOT_BUCKET,\n",
    "                persistent_metadata_path_new,\n",
    "                local_metadata_file,\n",
    "                content_type=\"text/csv\"\n",
    "            )\n",
    "    \n",
    "            os.remove(local_metadata_file)\n",
    "            print(f\" Updated/uploaded metadata for '{kingdom_safe}-{cls_safe}' â†’ {persistent_metadata_path_new}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Cleanup local temp\n",
    "        os.remove(LOCAL_METADATA)\n",
    "        print(\" Cleaned up local metadata files.\")\n",
    "    \n",
    "    else:\n",
    "        print(\" No new images moved; skipping metadata upload.\")\n",
    "    \n",
    "    # ==============================\n",
    "    # 6. Cleanup Temporal Landing (files only)\n",
    "    # ==============================\n",
    "    print(\" Cleaning up Temporal_Landing zone (files only)...\")\n",
    "    \n",
    "    try:\n",
    "        temporal_objects = list(client.list_objects(ROOT_BUCKET, prefix=f\"{TEMP_PREFIX}/\", recursive=True))\n",
    "        if not temporal_objects:\n",
    "            print(\" Temporal_Landing is already empty.\")\n",
    "        else:\n",
    "            deleted_count = 0\n",
    "            for obj in temporal_objects:\n",
    "                # Skip the temporal-landing folder itself \n",
    "                if (obj.object_name == f\"{TEMP_PREFIX}/\" or \n",
    "                    obj.object_name == f\"{TEMP_PREFIX}\"):\n",
    "                    continue\n",
    "    \n",
    "                client.remove_object(ROOT_BUCKET, obj.object_name)\n",
    "                print(f\" Deleted file: {obj.object_name}\")\n",
    "                deleted_count += 1\n",
    "    \n",
    "            print(f\" Cleaned up {deleted_count} files from Temporal-Landing (folders kept).\")\n",
    "    except Exception as e:\n",
    "        print(f\" Warning: Failed to fully clean Temporal_Landing â†’ {e}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\" Persistent Landing Zone completed successfully.\")\n",
    "\n",
    "process_landing_zone();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6b423-d61b-49eb-9244-762717de63c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d77fb86-9f49-4628-a266-53de811d425e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
