{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63edc53b-d9a5-4cc4-ac58-2b833c652536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created 'Persistent_Landing' inside 'temporal-zone'.\n",
      "ðŸ“¥ Loading metadata from Temporal_Landing...\n",
      " Loaded metadata with 16 records.\n",
      " Checking existing images in Persistent_Landing...\n",
      " Found 0 existing images in Persistent_Landing.\n",
      " Error processing temporal-landing/images/img_0_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_0_1761519585.jpg, request_id: 18722F5581057848, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_0_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_1_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_1_1761519585.jpg, request_id: 18722F5581406269, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_1_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_2_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_2_1761519585.jpg, request_id: 18722F55817C4373, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_2_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_3_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_3_1761519585.jpg, request_id: 18722F5581AE3400, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_3_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_4_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_4_1761519585.jpg, request_id: 18722F5581D3D74C, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_4_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_5_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_5_1761519585.jpg, request_id: 18722F5581FF7671, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_5_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_6_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_6_1761519585.jpg, request_id: 18722F55822CAF04, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_6_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_7_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_7_1761519585.jpg, request_id: 18722F55825889EF, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_7_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_8_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_8_1761519585.jpg, request_id: 18722F55828A43CA, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_8_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_9_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_9_1761519585.jpg, request_id: 18722F5582BB5BE8, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_9_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_10_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_10_1761519585.jpg, request_id: 18722F5582F0865A, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_10_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_11_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_11_1761519585.jpg, request_id: 18722F558324AD63, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_11_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_12_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_12_1761519585.jpg, request_id: 18722F5583591B86, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_12_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_13_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_13_1761519585.jpg, request_id: 18722F55839689E2, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_13_1761519585.jpg\n",
      " Error processing temporal-landing/images/img_14_1761519585.jpg: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /temporal-zone/temporal-landing/images/img_14_1761519585.jpg, request_id: 18722F5583C17295, host_id: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8, bucket_name: temporal-zone, object_name: temporal-landing/images/img_14_1761519585.jpg\n",
      " Moved temporal-landing/images/258761a9-be1e-4885-9d27-dd613ba4bde2.jpg â†’ persistent_landing/images/Animalia/Squamata/Boidae/imperator/258761a9-be1e-4885-9d27-dd613ba4bde2.jpg\n",
      " Updating kingdom-class based metadata files...\n",
      " Updated/uploaded metadata for 'Animalia-Squamata' â†’ persistent_landing/metadata/Animalia_Squamata_metadata_2025_10_27_00:47.csv\n",
      " Cleaned up local metadata files.\n",
      " Cleaning up Temporal_Landing zone (files only)...\n",
      " Deleted file: temporal-landing/.init\n",
      " Deleted file: temporal-landing/images/258761a9-be1e-4885-9d27-dd613ba4bde2.jpg\n",
      " Deleted file: temporal-landing/metadata/metadata_final.csv\n",
      " Cleaned up 3 files from Temporal-Landing (folders kept).\n",
      " Persistent Landing Zone completed successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-Arman Bazarchi-\n",
    "Persistent_Landing Zone\n",
    "here we retrieve the stored raw data in temporal-landing and place them more organized in persistent-landing.\n",
    "connects to minIO and creates a persistent_landing subbucket in temporal-zone bucket,\n",
    "raises an error if the temporal_landing subbucket or temporal-zone bucket does not exist.\n",
    "saves text data in a csv file in a folder 'metadata',\n",
    "saves each image in its specie folder inside its family folder, inside its class, inside the kingdom it belongs to.\n",
    "so we ensure organized data having easy access to each one.\n",
    "example path of each image: temporal-zone/persistent_landing/images/{kingdom}/{class}/{family}/{specie}/{img_uuid}.jpg\n",
    "it avoids storing duplicate data in persistent_landing.\n",
    "in end removes temporary files from local storage and delets the temporal_landing as we have now moved the data to persistent.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from minio import Minio\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# ==============================\n",
    "#          Functions\n",
    "# ==============================\n",
    "\n",
    "def setup_minio_client_and_buckets(minio, access_key, secret_key, root_bucket, temp_prefix, persist_prefix):\n",
    "    # Setup MinIO client and validate/create buckets.\n",
    "    \n",
    "    client = Minio(\n",
    "        minio,\n",
    "        access_key=access_key,\n",
    "        secret_key=secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    # Validate bucket\n",
    "    if not client.bucket_exists(root_bucket):\n",
    "        sys.exit(f\" ERROR: Root bucket {root_bucket} does not exist in MinIO.\")\n",
    "    \n",
    "    temporal_exists = any(\n",
    "        obj.object_name.startswith(f\"{temp_prefix}/\")\n",
    "        for obj in client.list_objects(root_bucket, recursive=False)\n",
    "    )\n",
    "    if not temporal_exists:\n",
    "        sys.exit(f\" ERROR: {temp_prefix} does not exist inside 'Landing' bucket.\")\n",
    "    \n",
    "    # Create Persistent_Landing if missing\n",
    "    persistent_exists = any(\n",
    "        obj.object_name.startswith(f\"{persist_prefix}/\")\n",
    "        for obj in client.list_objects(root_bucket, recursive=False)\n",
    "    )\n",
    "    if not persistent_exists:\n",
    "        client.put_object(\n",
    "            root_bucket,\n",
    "            f\"{persist_prefix}/.init\",\n",
    "            data=io.BytesIO(b\"init\"),\n",
    "            length=4,\n",
    "            content_type=\"text/plain\"\n",
    "        )\n",
    "        print(f\" Created {persist_prefix} inside '{root_bucket}'.\")\n",
    "    \n",
    "    return client\n",
    "\n",
    "def load_metadata_from_temporal(client, root_bucket, temp_prefix):\n",
    "    # Load metadata from Temporal_Landing.\n",
    "    \n",
    "    print(f\" Loading metadata from {temp_prefix}...\")\n",
    "    local_metadata = \"temp_metadata.csv\"\n",
    "    temp_metadata_path = f\"{temp_prefix}/metadata/metadata_final.csv\"\n",
    "    try:\n",
    "        client.fget_object(root_bucket, temp_metadata_path, local_metadata)\n",
    "    except Exception as e:\n",
    "        sys.exit(f\" ERROR: Failed to find metadata at {temp_metadata_path} â†’ {e}\")\n",
    "    \n",
    "    metadata_df = pd.read_csv(local_metadata)\n",
    "    print(f\" Loaded metadata with {len(metadata_df)} records.\")\n",
    "    return metadata_df, local_metadata\n",
    "\n",
    "def scan_existing_persistent_images(client, root_bucket, persist_prefix):\n",
    "    # Scan existing images in Persistent_Landing.\n",
    "    # to skip duplicates.\n",
    "    \n",
    "    print(f\" Checking existing images in {persist_prefix}...\")\n",
    "    existing_persistent_uuids = set()\n",
    "    for obj in client.list_objects(root_bucket, prefix=f\"{persist_prefix}/images/\", recursive=True):\n",
    "        match = re.match(rf\"{persist_prefix}/images/.+?/([a-f0-9\\-]+)\\.jpg\", obj.object_name)\n",
    "        if match:\n",
    "            existing_persistent_uuids.add(match.group(1))\n",
    "    \n",
    "    print(f\" Found {len(existing_persistent_uuids)} existing images in Persistent_Landing.\")\n",
    "    return existing_persistent_uuids\n",
    "\n",
    "def move_single_image(client, root_bucket, persist_prefix, row, existing_persistent_uuids):\n",
    "    # Move a single image from Temporal to Persistent.\n",
    "    # we move them one by one to make sure both image and metadata of a specific observation is recorder,\n",
    "    # and we wont have maybe some metadata without valid image.\n",
    "    try:\n",
    "        img_uuid = row.get(\"uuid\")\n",
    "        if not img_uuid:\n",
    "            return None, False\n",
    "        \n",
    "        # Skip if image already exists in Persistent\n",
    "        if img_uuid in existing_persistent_uuids:\n",
    "            print(f\" Skipping duplicate UUID: {img_uuid}\")\n",
    "            return None, False\n",
    "        \n",
    "        object_name = row.get(\"temporal_path\") \n",
    "        src_path = object_name\n",
    "        \n",
    "        kingdom = str(row.get(\"kingdom\", \"Unknown\")).replace(\" \", \"_\")\n",
    "        cls = str(row.get(\"class\", \"Unknown\")).replace(\" \", \"_\")\n",
    "        family = str(row.get(\"family\", \"Unknown\")).replace(\" \", \"_\")\n",
    "        specie = str(row.get(\"species\", \"Unknown\")).replace(\" \", \"_\")\n",
    "        \n",
    "        # Destination path \n",
    "        dest_path = f\"{persist_prefix}/images/{kingdom}/{cls}/{family}/{specie}/{img_uuid}.jpg\"\n",
    "        \n",
    "        # Download image from Temporal\n",
    "        data = client.get_object(root_bucket, src_path)\n",
    "        image_bytes = data.read()\n",
    "        data.close()\n",
    "        data.release_conn()\n",
    "        \n",
    "        # Upload image to Persistent\n",
    "        client.put_object(\n",
    "            root_bucket,\n",
    "            dest_path,\n",
    "            data=io.BytesIO(image_bytes),\n",
    "            length=len(image_bytes),\n",
    "            content_type=\"image/jpeg\"\n",
    "        )\n",
    "        \n",
    "        existing_persistent_uuids.add(img_uuid)\n",
    "        print(f\" Moved {src_path} â†’ {dest_path}\")\n",
    "        \n",
    "        return dest_path, True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {object_name}: {e}\")\n",
    "        return None, False\n",
    "\n",
    "def process_metadata_group(client, root_bucket, persist_prefix, kingdom_name, cls_name, group):\n",
    "    # Process metadata for a single kingdom-class group.\n",
    "    \n",
    "    kingdom_safe = str(kingdom_name).replace(\" \", \"_\")\n",
    "    cls_safe = str(cls_name).replace(\" \", \"_\")\n",
    "    \n",
    "    # Create a new filename with current timestamp for updated metadata\n",
    "    timestamp = datetime.now().strftime(\"%Y_%m_%d_%H:%M\")\n",
    "    metadata_filename = f\"{kingdom_safe}_{cls_safe}_metadata_{timestamp}.csv\"\n",
    "    local_metadata_file = f\"{kingdom_safe}_{cls_safe}_metadata_temp.csv\"\n",
    "    persistent_metadata_dir = f\"{persist_prefix}/metadata/\"\n",
    "    \n",
    "    # Look for any existing metadata file for this kingdom+class\n",
    "    existing_metadata_files = [\n",
    "        obj.object_name for obj in client.list_objects(root_bucket, prefix=persistent_metadata_dir, recursive=True)\n",
    "        if re.match(rf\"{persistent_metadata_dir}{kingdom_safe}_{cls_safe}_metadata_.*\\.csv\", obj.object_name)\n",
    "    ]\n",
    "    \n",
    "    if existing_metadata_files:\n",
    "        # Take the latest metadata file \n",
    "        existing_metadata_files.sort(reverse=True)\n",
    "        existing_metadata_path = existing_metadata_files[0]\n",
    "        existing_local_file = f\"existing_{kingdom_safe}_{cls_safe}.csv\"\n",
    "        client.fget_object(root_bucket, existing_metadata_path, existing_local_file)\n",
    "        \n",
    "        # Read existing metadata\n",
    "        existing_df = pd.read_csv(existing_local_file)\n",
    "        \n",
    "        # Delete old file from Persistent\n",
    "        client.remove_object(root_bucket, existing_metadata_path)\n",
    "        os.remove(existing_local_file)\n",
    "        \n",
    "        # Merge Temporal rows that are not already in Persistent\n",
    "        new_rows = group[~group[\"uuid\"].isin(existing_df[\"uuid\"])]\n",
    "        merged_df = pd.concat([existing_df, new_rows], ignore_index=True)\n",
    "    else:\n",
    "        # No existing metadata -> use all rows from Temporal\n",
    "        group[\"persistent_path\"]\n",
    "        merged_df = group\n",
    "    \n",
    "    # Save merged metadata with updated timestamp\n",
    "    merged_df.to_csv(local_metadata_file, index=False)\n",
    "    persistent_metadata_path_new = f\"{persistent_metadata_dir}{metadata_filename}\"\n",
    "    client.fput_object(\n",
    "        root_bucket,\n",
    "        persistent_metadata_path_new,\n",
    "        local_metadata_file,\n",
    "        content_type=\"text/csv\"\n",
    "    )\n",
    "    \n",
    "    os.remove(local_metadata_file)\n",
    "    print(f\" Updated/uploaded metadata for '{kingdom_safe}-{cls_safe}' â†’ {persistent_metadata_path_new}\")\n",
    "\n",
    "def cleanup_temporal_landing(client, root_bucket, temp_prefix):\n",
    "    # Cleanup Temporal Landing.\n",
    "    print(\" Cleaning up Temporal_Landing zone (files only)...\")\n",
    "    \n",
    "    try:\n",
    "        temporal_objects = list(client.list_objects(root_bucket, prefix=f\"{temp_prefix}/\", recursive=True))\n",
    "        if not temporal_objects:\n",
    "            print(\" Temporal_Landing is already empty.\")\n",
    "        else:\n",
    "            deleted_count = 0\n",
    "            for obj in temporal_objects:\n",
    "                # Skip the temporal-landing folder itself \n",
    "                if (obj.object_name == f\"{temp_prefix}/\" or \n",
    "                    obj.object_name == f\"{temp_prefix}\"):\n",
    "                    continue\n",
    "                \n",
    "                client.remove_object(root_bucket, obj.object_name)\n",
    "                print(f\" Deleted file: {obj.object_name}\")\n",
    "                deleted_count += 1\n",
    "            \n",
    "            print(f\" Cleaned up {deleted_count} files from Temporal-Landing (folders kept).\")\n",
    "    except Exception as e:\n",
    "        print(f\" Warning: Failed to fully clean Temporal_Landing â†’ {e}\")\n",
    "\n",
    "# ==============================\n",
    "#       Configuration\n",
    "# ==============================\n",
    "def process_landing_zone(\n",
    "    minio=\"localhost:9000\", # default configurations\n",
    "    access_key=\"admin\",\n",
    "    secret_key=\"password123\"): \n",
    "    \n",
    "    root_bucket=\"temporal-zone\" # main bucket\n",
    "    temp_prefix=\"temporal-landing\" # source bucket\n",
    "    persist_prefix=\"persistent_landing\" # destination bucket\n",
    "    \n",
    "    # Setup MinIO client and buckets\n",
    "    client = setup_minio_client_and_buckets(minio, access_key, secret_key, root_bucket, temp_prefix, persist_prefix)\n",
    "    \n",
    "    # Load metadata from Temporal_Landing\n",
    "    metadata_df, local_metadata = load_metadata_from_temporal(client, root_bucket, temp_prefix)\n",
    "    \n",
    "    # Scan existing Persistent images by UUID\n",
    "    existing_persistent_uuids = scan_existing_persistent_images(client, root_bucket, persist_prefix)\n",
    "    metadata_df[\"persistent_path\"] = None\n",
    "    \n",
    "    # Move images from Temporal -> Persistent\n",
    "    moved_records = []\n",
    "    \n",
    "    for idx, row in metadata_df.iterrows():\n",
    "        dest_path, success = move_single_image(client, root_bucket, persist_prefix, row, existing_persistent_uuids)\n",
    "        if success:\n",
    "            metadata_df.loc[idx, \"persistent_path\"] = dest_path\n",
    "            moved_records.append(row)\n",
    "    \n",
    "    # Save or merge metadata files by (Kingdom, Class)\n",
    "    if not metadata_df.empty:\n",
    "        print(\" Updating kingdom-class based metadata files...\")\n",
    "        \n",
    "        for (kingdom_name, cls_name), group in metadata_df.groupby([\"kingdom\", \"class\"]):\n",
    "            process_metadata_group(client, root_bucket, persist_prefix, kingdom_name, cls_name, group)\n",
    "        \n",
    "        # Cleanup local temp\n",
    "        os.remove(local_metadata)\n",
    "        print(\" Cleaned up local metadata files.\")\n",
    "    else:\n",
    "        print(\" No new images moved; skipping metadata upload.\")\n",
    "    \n",
    "    # Cleanup Temporal Landing (files only)\n",
    "    cleanup_temporal_landing(client, root_bucket, temp_prefix)\n",
    "    \n",
    "    print(\" Persistent Landing Zone completed successfully.\")\n",
    "\n",
    "process_landing_zone();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6b423-d61b-49eb-9244-762717de63c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d77fb86-9f49-4628-a266-53de811d425e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
