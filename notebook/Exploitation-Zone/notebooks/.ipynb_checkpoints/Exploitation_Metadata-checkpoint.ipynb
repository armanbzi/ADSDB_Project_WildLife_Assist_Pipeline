{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7efffba4-8f04-497e-ad59-661dfd733e39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 125\u001b[39m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m New records to embed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(new_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# 4. Generate and add embeddings\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnew_df\u001b[49m.empty:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m No new metadata to embed. No data was added.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'new_df' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-Arman Bazarchi-\n",
    "Exploitation Zone — Metadata notebook\n",
    "\n",
    " - Read trusted metadata CSV(s) from trusted-zone\n",
    " - merges values of needed columns of a row into a single string for embedding\n",
    " - we keep up to kingdom because model can be used to hold and integrate data of different kingdoms\n",
    " - (Animalia, Plante, Fungi)\n",
    " - Create text embeddings for text metadata using ChromaDB\n",
    " - Avoid duplicates by checking existing uuids in the collection\n",
    " - Store embeddings persistently for similarity search\n",
    " - we store them in a chroma directory 'exploitation_db' in the 'metadata_embeddings' collection.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from minio import Minio\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import os, io\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------\n",
    "# 1. Configuration\n",
    "# -----------------------\n",
    "def process_exploitation_metadata(\n",
    "    MINIO = \"localhost:9000\",\n",
    "    ACCESS_KEY = \"admin\",\n",
    "    SECRET_KEY = \"password123\"):\n",
    "\n",
    "    TRUSTED_ZONE = \"trusted-zone\"\n",
    "    TRUSTED_META_PREFIX = \"metadata/\"\n",
    "    \n",
    "    # set the working directory\n",
    "    try:\n",
    "        SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__)) # in orchestrated\n",
    "    except NameError:\n",
    "        SCRIPT_DIR = os.getcwd() # in notebook\n",
    "        \n",
    "    CHROMA_DB = os.path.join(SCRIPT_DIR, \"../Exploitation-Zone/exploitation_db\")\n",
    "\n",
    "    COLLECTION_NAME = \"metadata_embeddings\"    \n",
    "    \n",
    "    #  Connect to MinIO\n",
    "    client = Minio(MINIO, access_key=ACCESS_KEY, secret_key=SECRET_KEY, secure=False)\n",
    "    \n",
    "    # raise error if no trusted-zone \n",
    "    if not client.bucket_exists(TRUSTED_ZONE):\n",
    "        raise SystemExit(f\" Trusted zone bucket '{TRUSTED_ZONE}' does not exist. Cannot continue.\")\n",
    "    \n",
    "    \n",
    "    # List all metadata CSVs from trusted-zone\n",
    "    metadata_objs = [\n",
    "        obj.object_name for obj in client.list_objects(TRUSTED_ZONE, prefix=TRUSTED_META_PREFIX, recursive=True)\n",
    "        if obj.object_name.lower().endswith(\".csv\")]\n",
    "    \n",
    "    # raise error if no metadata available\n",
    "    if not metadata_objs:\n",
    "        raise SystemExit(\" No trusted metadata files found in trusted-zone.\")\n",
    "    \n",
    "    # Use the latest trusted metadata\n",
    "    metadata_objs.sort(reverse=True)\n",
    "    latest_meta = metadata_objs[0]\n",
    "    print(f\" Loading trusted metadata: {latest_meta}\")\n",
    "    \n",
    "    # Download to memory\n",
    "    resp = client.get_object(TRUSTED_ZONE, latest_meta)\n",
    "    data = resp.read()\n",
    "    resp.close()\n",
    "    resp.release_conn()\n",
    "    metadata_df = pd.read_csv(io.BytesIO(data))\n",
    "    print(f\" Loaded trusted metadata with {len(metadata_df)} rows.\")\n",
    "    \n",
    "    # -----------------------\n",
    "    # 2. Combine text columns for embedding\n",
    "    # -----------------------\n",
    "    text_cols = [\"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\", \"scientific_name\", \"common\"]\n",
    "    metadata_df[\"combined_text\"] = metadata_df[text_cols].fillna(\"\").agg(\" \".join, axis=1).str.strip()\n",
    "    \n",
    "    # Drop rows without valid UUID or text\n",
    "    metadata_df = metadata_df.dropna(subset=[\"uuid\", \"combined_text\"])\n",
    "    metadata_df = metadata_df[metadata_df[\"combined_text\"].str.len() > 0]\n",
    "    print(f\" Cleaned metadata for embedding: {len(metadata_df)} valid rows.\")\n",
    "    \n",
    "    \n",
    "    #  Connect to ChromaDB \n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_DB)\n",
    "    \n",
    "    # Create or load the collection\n",
    "    collection = chroma_client.get_or_create_collection(\n",
    "        name=COLLECTION_NAME,\n",
    "        metadata={\"description\": \"Embeddings for trusted metadata records\"}\n",
    "    )\n",
    "    \n",
    "    # Use default text embedding function\n",
    "    text_embedder = embedding_functions.DefaultEmbeddingFunction()\n",
    "    \n",
    "    # -----------------------\n",
    "    # 3. Avoid duplicates — check existing UUIDs\n",
    "    # -----------------------\n",
    "    existing_count = collection.count()\n",
    "    \n",
    "    # Get all existing UUIDs here stored as 'ids' (if collection is not empty)\n",
    "    existing_ids = []\n",
    "    if existing_count > 0:\n",
    "        batch_size = 500\n",
    "        offset = 0\n",
    "        while True:\n",
    "            batch = collection.get(limit=batch_size, offset=offset)\n",
    "            if not batch[\"ids\"]:\n",
    "                break\n",
    "            existing_ids.extend(batch[\"ids\"])\n",
    "            offset += batch_size\n",
    "    \n",
    "    existing_ids = set(existing_ids)\n",
    "    print(f\" Existing embeddings in collection: {len(existing_ids)}\")\n",
    "    \n",
    "    # Filter new rows\n",
    "    new_df = metadata_df[~metadata_df[\"uuid\"].isin(existing_ids)]\n",
    "    print(f\" New records to embed: {len(new_df)}\")\n",
    "    \n",
    "    # -----------------------\n",
    "    # 4. Generate and add embeddings\n",
    "    # -----------------------\n",
    "    if new_df.empty:\n",
    "        print(\" No new metadata to embed. No data was added.\")\n",
    "    else:\n",
    "        texts = new_df[\"combined_text\"].tolist()\n",
    "        uuids = new_df[\"uuid\"].tolist()\n",
    "    \n",
    "        print(\" Generating embeddings...\")\n",
    "        embeddings = text_embedder(texts)\n",
    "    \n",
    "        # setting a barch size to avoid exceeding the maximum allowed limit(5461)\n",
    "        batch_size = 5000\n",
    "        total = len(uuids)\n",
    "        start_idx = 0\n",
    "    \n",
    "        print(f\" Adding {total} new embeddings to collection '{COLLECTION_NAME}' in batches...\")\n",
    "    \n",
    "        while start_idx < total:\n",
    "            end_idx = min(start_idx + batch_size, total)\n",
    "    \n",
    "            try:\n",
    "                collection.add(\n",
    "                    ids=uuids[start_idx:end_idx],\n",
    "                    embeddings=embeddings[start_idx:end_idx],\n",
    "                    metadatas=new_df.iloc[start_idx:end_idx].to_dict(orient=\"records\"),\n",
    "                    documents=texts[start_idx:end_idx],\n",
    "                )\n",
    "                print(f\"  Added records {start_idx + 1}-{end_idx} / {total}\")\n",
    "                start_idx = end_idx  # move to next batch\n",
    "    \n",
    "            except Exception as e:\n",
    "                print(f\"   Batch {start_idx + 1}-{end_idx} failed: {e}\")\n",
    "    \n",
    "                # If batch too big, reduce size and retry\n",
    "                if \"max batch size\" in str(e).lower() and batch_size > 1000:\n",
    "                    old_batch = batch_size\n",
    "                    batch_size = batch_size // 2\n",
    "                    print(f\"  Reducing batch size from {old_batch} → {batch_size} and retrying...\")\n",
    "                else:\n",
    "                    raise\n",
    "    \n",
    "        print(f\"  Added {total} new embeddings to collection '{COLLECTION_NAME}'.\")\n",
    "    \n",
    "    \n",
    "    #  Summary\n",
    "    final_count = collection.count()\n",
    "    added_count = final_count - existing_count\n",
    "    \n",
    "    print(\"\\n ===== Summary =====\")\n",
    "    print(f\" Collection: {COLLECTION_NAME}\")\n",
    "    print(f\" Previously had: {existing_count}\")\n",
    "    print(f\" New added: {added_count}\")\n",
    "    print(f\" Total now: {final_count}\")\n",
    "    print(\"=======================\")\n",
    "    print(\" Exploitation Metadata processing complete.\")\n",
    "\n",
    "process_exploitation_metadata();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64413288-6e8d-4616-a423-0936aaf06068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
