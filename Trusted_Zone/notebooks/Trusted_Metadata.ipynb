{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7efffba4-8f04-497e-ad59-661dfd733e39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 12 duplicate rows by uuid.\n",
      "Removed 79 rows missing uuid or formatted_path.\n",
      " Removed old trusted metadata file: metadata/trusted_metadata_2025_10_29_07_18_26.csv\n",
      " No new rows to add; trusted metadata is up to date.\n",
      " Trusted metadata uploaded: metadata/trusted_metadata_2025_10_29_07_29_23.csv\n",
      " Trusted metadata processing complete.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-Arman Bazarchi-\n",
    "Trusted Zone â€” Metadata notebook\n",
    "\n",
    "   Here we apply some cleaning on text data and move from fomatted-zone to trusted-zone\n",
    "   connects to minIO, creates trusted-zone bucket, raises an error if formatted-zone does not exist.\n",
    "   removes rows with missing id or a correct image path, makes sure of normality of all columns.\n",
    "   text data gets normalized for another time here to ensure it completely.\n",
    "   replaces missing valaues with 'none',\n",
    "   \n",
    "   avoiding storing duplicate data in formatted-zone, also removes any temporal file in local storage.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from minio import Minio\n",
    "import pandas as pd\n",
    "import io, os, shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------\n",
    "#    Configuration\n",
    "# -----------------------\n",
    "def process_trusted_metadata(\n",
    "    MINIO = \"localhost:9000\",\n",
    "    ACCESS_KEY = \"admin\",\n",
    "    SECRET_KEY = \"password123\"):\n",
    "\n",
    "    FORMATTED_ZONE = \"formatted-zone\"\n",
    "    TRUSTED_ZONE = \"trusted-zone\"\n",
    "    \n",
    "    META_PREFIX = \"metadata/\"\n",
    "    \n",
    "    TARGET_COLUMNS = [\n",
    "        \"uuid\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\",\n",
    "        \"genus\", \"species\", \"scientific_name\", \"common\",\n",
    "        \"persistent_path\", \"formatted_path\", \"image_url\"\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    #  Connect to MinIO\n",
    "    client = Minio(MINIO, access_key=ACCESS_KEY, secret_key=SECRET_KEY, secure=False)\n",
    "    if not client.bucket_exists(TRUSTED_ZONE):\n",
    "        client.make_bucket(TRUSTED_ZONE)\n",
    "        print(f\" Created trusted zone bucket: {TRUSTED_ZONE}\")\n",
    "    \n",
    "    # -------------------------------------\n",
    "    #   Read all formatted metadata files\n",
    "    # -------------------------------------\n",
    "    metadata_objs = [\n",
    "        obj.object_name for obj in client.list_objects(FORMATTED_ZONE, prefix=META_PREFIX, recursive=True)\n",
    "        if obj.object_name.lower().endswith(\".csv\")\n",
    "    ]\n",
    "    \n",
    "    if not metadata_objs:\n",
    "        raise SystemExit(\" No formatted metadata files found.\")\n",
    "    \n",
    "    all_dfs = []\n",
    "    for obj_name in metadata_objs:\n",
    "        resp = client.get_object(FORMATTED_ZONE, obj_name)\n",
    "        data = resp.read()\n",
    "        resp.close()\n",
    "        resp.release_conn()\n",
    "        df = pd.read_csv(io.BytesIO(data))\n",
    "        all_dfs.append(df)\n",
    "    \n",
    "    #  all formatted metadata\n",
    "    metadata_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    \n",
    "    # --------------------------\n",
    "    #    Trusted Zone cleaning\n",
    "    # --------------------------\n",
    "    \n",
    "    # Keep only target columns\n",
    "    for col in TARGET_COLUMNS:\n",
    "        if col not in metadata_df.columns:\n",
    "            metadata_df[col] = pd.NA\n",
    "    metadata_df = metadata_df[TARGET_COLUMNS]\n",
    "    \n",
    "    #  Remove duplicates by uuid\n",
    "    before_dupe = len(metadata_df)\n",
    "    metadata_df = metadata_df.drop_duplicates(subset=[\"uuid\"], keep=\"first\").reset_index(drop=True)\n",
    "    after_dupe = len(metadata_df)\n",
    "    print(f\"Removed {before_dupe - after_dupe} duplicate rows by uuid.\")\n",
    "    \n",
    "    #  Remove rows missing uuid or formatted_path\n",
    "    before_missing = len(metadata_df)\n",
    "    metadata_df = metadata_df[metadata_df[\"uuid\"].notna()]\n",
    "    metadata_df = metadata_df[metadata_df[\"formatted_path\"].notna()]\n",
    "    after_missing = len(metadata_df)\n",
    "    print(f\"Removed {before_missing - after_missing} rows missing uuid or formatted_path.\")\n",
    "    \n",
    "    #  Normalize strings\n",
    "    str_cols = [\"kingdom\",\"phylum\",\"class\",\"order\",\"family\",\"genus\",\"species\",\"scientific_name\",\"common\",\"persistent_path\",\"formatted_path\",\"image_url\"]\n",
    "    for col in str_cols:\n",
    "        metadata_df[col] = metadata_df[col].astype(\"string\").str.strip().replace({\"\": pd.NA})\n",
    "    \n",
    "    #  \"None\" strings with pd.NA\n",
    "    metadata_df.replace({\"NA\": pd.NA, \"None\": pd.NA}, inplace=True)\n",
    "    \n",
    "    \n",
    "    # -----------------------\n",
    "    #  Merge with existing trusted metadata (avoid duplicates)\n",
    "    # -----------------------\n",
    "    trusted_metadata_files = [\n",
    "        obj.object_name for obj in client.list_objects(TRUSTED_ZONE, prefix=META_PREFIX, recursive=True)\n",
    "        if obj.object_name.lower().endswith(\".csv\") and \"trusted_metadata_\" in obj.object_name\n",
    "    ]\n",
    "    \n",
    "    if trusted_metadata_files:\n",
    "        # Take the latest trusted metadata CSV\n",
    "        trusted_metadata_files.sort(reverse=True)\n",
    "        latest_file = trusted_metadata_files[0]\n",
    "        local_existing = \"temp_existing_trusted_metadata.csv\"\n",
    "    \n",
    "        # Download existing trusted metadata\n",
    "        client.fget_object(TRUSTED_ZONE, latest_file, local_existing)\n",
    "        existing_trusted_df = pd.read_csv(local_existing)\n",
    "    \n",
    "        # Remove old trusted metadata files \n",
    "        for obj in client.list_objects(TRUSTED_ZONE, prefix=META_PREFIX, recursive=True):\n",
    "            if obj.object_name.startswith(\"metadata/trusted_metadata_\"):\n",
    "                client.remove_object(TRUSTED_ZONE, obj.object_name)\n",
    "                print(f\" Removed old trusted metadata file: {obj.object_name}\")\n",
    "    \n",
    "        # Merge only new rows \n",
    "        new_rows = metadata_df[~metadata_df[\"uuid\"].isin(existing_trusted_df[\"uuid\"])]\n",
    "        if not new_rows.empty:\n",
    "            metadata_df = pd.concat([existing_trusted_df, new_rows], ignore_index=True)\n",
    "            print(f\" Added {len(new_rows)} new rows to trusted metadata, total now: {len(metadata_df)}\")\n",
    "        else:\n",
    "            print(\" No new rows to add; trusted metadata is up to date.\")\n",
    "    \n",
    "        # Cleanup local temp\n",
    "        os.remove(local_existing)\n",
    "    else:\n",
    "        print(\" No existing trusted metadata found; creating new one.\")\n",
    "    \n",
    "    # -----------------------\n",
    "    #    Save cleaned metadata to Trusted Zone\n",
    "    # -----------------------\n",
    "    timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    local_file = f\"trusted_metadata_{timestamp}.csv\"\n",
    "    os.makedirs(\"temp_trusted\", exist_ok=True)\n",
    "    local_path = os.path.join(\"temp_trusted\", local_file)\n",
    "    metadata_df.to_csv(local_path, index=False)\n",
    "    \n",
    "    # Upload to MinIO trusted-zone/metadata/\n",
    "    client.fput_object(TRUSTED_ZONE, f\"{META_PREFIX}{local_file}\", local_path, content_type=\"text/csv\")\n",
    "    print(f\" Trusted metadata uploaded: {META_PREFIX}{local_file}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    os.remove(local_path)\n",
    "    shutil.rmtree(\"temp_trusted\")\n",
    "    print(\" Trusted metadata processing complete.\")\n",
    "\n",
    "process_trusted_metadata();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8297a70b-1b0e-4824-9afb-823b0afeecee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
