{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d6c8f0-73c5-4f6b-8145-099841999c24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Formatted Zone bucket already exists: formatted-zone\n",
      "üìÇ Found 1 metadata files to process.\n",
      "üîç Reading: persistent_landing/metadata/Animalia_Squamata_metadata_2025_10_20_00:04.csv\n",
      "‚ö†Ô∏è No existing general metadata found, creating new one\n",
      "‚úÖ Adding 4932 new rows to general metadata, total now: 4932\n",
      "‚úÖ Formatted metadata updated successfully\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-Arman Bazarchi-\n",
    "Formatted_Metadata\n",
    "Here we ensure the format of only text metadata we had in persistent_landing and move to formatted-zone bucket.\n",
    "we normalize the data and remove any incomplete data.\n",
    "connects to minIO, creates formatted-zone bucket, raises an error if pesistant_landing or temporal-zone does not exist.\n",
    "read data from persistent and normilize then store in formatted-zone, \n",
    "here we save a csv file, a .parquet file, a .json file, a schema summary of our text metadata for different uses in future.\n",
    "it avoids storing duplicate data in formatted-zone, also removes any temporal file in local storage.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from minio import Minio\n",
    "import pandas as pd\n",
    "import io, json, os, re, shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# ==============================\n",
    "# 1. Configuration\n",
    "# ==============================\n",
    "MINIO_ENDPOINT = \"localhost:9000\"\n",
    "ACCESS_KEY = \"admin\"\n",
    "SECRET_KEY = \"password123\"\n",
    "LANDING_ZONE = \"landing-zone\"\n",
    "PERSIST_PREFIX = \"persistent_landing\"\n",
    "FORMATTED_ZONE = \"formatted-zone\"\n",
    "\n",
    "\n",
    "#  Connect to MinIO\n",
    "client = Minio(\n",
    "    MINIO_ENDPOINT,\n",
    "    access_key=ACCESS_KEY,\n",
    "    secret_key=SECRET_KEY,\n",
    "    secure=False\n",
    ")\n",
    "# break if temporal landing or landing-zone does not exist\n",
    "if not client.bucket_exists(LANDING_ZONE):\n",
    "    sys.exit(\"‚ùå ERROR: Root bucket 'Landing' does not exist in MinIO.\")\n",
    "\n",
    "persistent_objects = list(client.list_objects(LANDING_ZONE, prefix=f\"{PERSIST_PREFIX}/\", recursive=False))\n",
    "if not persistent_objects:\n",
    "    raise Exception(\"‚ùå Required prefix '{PERSIST_PREFIX}/' not found inside 'temporal-landing' bucket.\")\n",
    "\n",
    "# Ensure formatted-zone bucket exists\n",
    "if not client.bucket_exists(FORMATTED_ZONE):\n",
    "    client.make_bucket(FORMATTED_ZONE)\n",
    "    print(f\"‚úÖ Created Formatted Zone bucket: {FORMATTED_ZONE}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Formatted Zone bucket already exists: {FORMATTED_ZONE}\")\n",
    "\n",
    "# ==============================\n",
    "# 2. List all metadata files in Persistent Landing\n",
    "# ==============================\n",
    "metadata_objects = [\n",
    "    obj.object_name for obj in client.list_objects(LANDING_ZONE, prefix=f\"{PERSIST_PREFIX}/metadata/\", recursive=True)\n",
    "    if obj.object_name.endswith(\".csv\") or obj.object_name.endswith(\".json\")\n",
    "]\n",
    "\n",
    "if not metadata_objects:\n",
    "    raise Exception(\"‚ö†Ô∏è No metadata files found in Persistent Landing Zone.\")\n",
    "\n",
    "print(f\"üìÇ Found {len(metadata_objects)} metadata files to process.\")\n",
    "\n",
    "# ==============================\n",
    "# 3. Read all metadata files from Persistent Landing\n",
    "# ==============================\n",
    "all_dfs = []\n",
    "\n",
    "for obj_name in metadata_objects:\n",
    "    print(f\"üîç Reading: {obj_name}\")\n",
    "    response = client.get_object(LANDING_ZONE, obj_name)\n",
    "    data = response.read()\n",
    "    response.close()\n",
    "    response.release_conn()\n",
    "\n",
    "    try:\n",
    "        if obj_name.endswith(\".csv\"):\n",
    "            df = pd.read_csv(io.BytesIO(data))\n",
    "        elif obj_name.endswith(\".json\"):\n",
    "            json_data = json.load(io.BytesIO(data))\n",
    "            df = pd.json_normalize(json_data)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        all_dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading {obj_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "if not all_dfs:\n",
    "    raise Exception(\"‚ö†Ô∏è No valid metadata could be loaded.\")\n",
    "\n",
    "# ==============================\n",
    "# 4. Normalize schema\n",
    "# ==============================\n",
    "target_columns = [\n",
    "    \"uuid\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\",\n",
    "    \"genus\", \"species\", \"scientific_name\", \"common\",\n",
    "    \"persistent_path\",\"formatted_path\", \"image_url\"\n",
    "]\n",
    "\n",
    "for i, df in enumerate(all_dfs):\n",
    "    for col in target_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    all_dfs[i] = df[target_columns]\n",
    "\n",
    "# Combine all Persistent metadata into one DataFrame\n",
    "persistent_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Generate formatted_path same as persistent_path\n",
    "persistent_df[\"formatted_path\"] = persistent_df[\"persistent_path\"].str.replace(\n",
    "    f\"{PERSIST_PREFIX}/images\", \"images\", regex=False\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# 5. Check for existing general metadata in Formatted Zone\n",
    "# ==============================\n",
    "general_metadata_files = [\n",
    "    obj.object_name for obj in client.list_objects(FORMATTED_ZONE, prefix=\"metadata/\", recursive=True)\n",
    "    if re.match(r\"metadata/all_metadata_.*\\.csv\", obj.object_name)\n",
    "]\n",
    "\n",
    "if general_metadata_files:\n",
    "    # Take the latest general metadata CSV\n",
    "    general_metadata_files.sort(reverse=True)\n",
    "    latest_metadata_file = general_metadata_files[0]\n",
    "    local_existing = \"temp_existing_metadata.csv\"\n",
    "\n",
    "    # Download existing metadata\n",
    "    client.fget_object(FORMATTED_ZONE, latest_metadata_file, local_existing)\n",
    "    general_df = pd.read_csv(local_existing)\n",
    "\n",
    "    # Delete the old file from formatted-zone\n",
    "    client.remove_object(FORMATTED_ZONE, latest_metadata_file)\n",
    "    # Remove old general formatted files\n",
    "    general_files_prefix = \"metadata/all_metadata\"\n",
    "    schema_files_prefix = \"metadata/schema_summary\"\n",
    "    # List all objects in formatted-zone/metadata\n",
    "    for obj in client.list_objects(FORMATTED_ZONE, prefix=\"metadata/\", recursive=True):\n",
    "        if obj.object_name.startswith(general_files_prefix) or obj.object_name.startswith(schema_files_prefix):\n",
    "            client.remove_object(FORMATTED_ZONE, obj.object_name)\n",
    "            print(f\"üóëÔ∏è Removed old file: {obj.object_name}\")\n",
    "\n",
    "    # Cleanup local temp\n",
    "    os.remove(local_existing)\n",
    "    print(f\"‚úÖ Loaded and removed existing general metadata with {len(general_df)} rows\")\n",
    "else:\n",
    "    # No general metadata exists yet\n",
    "    general_df = pd.DataFrame(columns=target_columns)\n",
    "    print(\"‚ö†Ô∏è No existing general metadata found, creating new one\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 6. Merge new rows and avoid duplicates\n",
    "# ==============================\n",
    "new_rows = persistent_df[~persistent_df[\"uuid\"].isin(general_df[\"uuid\"])]\n",
    "if not new_rows.empty:\n",
    "    updated_df = pd.concat([general_df, new_rows], ignore_index=True)\n",
    "    print(f\"‚úÖ Adding {len(new_rows)} new rows to general metadata, total now: {len(updated_df)}\")\n",
    "else:\n",
    "    updated_df = general_df\n",
    "    print(\"‚ö†Ô∏è No new rows to add; general metadata is up to date\")\n",
    "\n",
    "\n",
    "#  Schema summary\n",
    "schema_summary = pd.DataFrame({\n",
    "    \"column_name\": updated_df.columns,\n",
    "    \"dtype\": [str(updated_df[c].dtype) for c in updated_df.columns],\n",
    "    \"missing_values\": [updated_df[c].isna().sum() for c in updated_df.columns]\n",
    "})\n",
    "\n",
    "# ==============================\n",
    "# 7. Save unified outputs\n",
    "# ==============================\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H:%M\")\n",
    "os.makedirs(\"temp_formatted\", exist_ok=True)\n",
    "\n",
    "local_csv = \"temp_formatted/all_metadata.csv\"\n",
    "local_parquet = \"temp_formatted/all_metadata.parquet\"\n",
    "local_json = \"temp_formatted/all_metadata.json\"\n",
    "local_schema = \"temp_formatted/schema_summary.csv\"\n",
    "\n",
    "updated_df.to_csv(local_csv, index=False)\n",
    "updated_df.to_parquet(local_parquet, index=False)\n",
    "updated_df.to_json(local_json, orient=\"records\", lines=True)\n",
    "schema_summary.to_csv(local_schema, index=False)\n",
    "\n",
    "# Upload to MinIO\n",
    "client.fput_object(FORMATTED_ZONE, f\"metadata/all_metadata_{timestamp}.csv\", local_csv, content_type=\"text/csv\")\n",
    "client.fput_object(FORMATTED_ZONE, f\"metadata/all_metadata_{timestamp}.parquet\", local_parquet, content_type=\"application/octet-stream\")\n",
    "client.fput_object(FORMATTED_ZONE, f\"metadata/all_metadata_{timestamp}.json\", local_json, content_type=\"application/json\")\n",
    "client.fput_object(FORMATTED_ZONE, f\"metadata/schema_summary_{timestamp}.csv\", local_schema, content_type=\"text/csv\")\n",
    "\n",
    "# Cleanup\n",
    "os.remove(local_csv)\n",
    "os.remove(local_parquet)\n",
    "os.remove(local_json)\n",
    "os.remove(local_schema)\n",
    "shutil.rmtree(\"temp_formatted\")\n",
    "\n",
    "print(\"‚úÖ Formatted metadata updated successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dbbc16-78a4-44e2-be72-7030d6f9536d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
